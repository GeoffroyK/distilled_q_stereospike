{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Test on StereoSpike\n",
    "2025 - 08 - 07   \n",
    "Andres Brito\n",
    "- Verify dataset loading and network inference.\n",
    "    - Simplified Full-Precision without Skip  Connections (Tomo's result). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from spikingjelly.clock_driven import functional, surrogate, neuron, layer\n",
    "\n",
    "# StereoSpike Network (Model without skip connections --> Tomo's Modification)\n",
    "from network.SNN_models_simpl import Simplified_StereoSpike_NoSkip\n",
    "\n",
    "from network.metrics import MeanDepthError_original, OnePixelAccuracy, log_to_lin_depths, disparity_to_depth, depth_to_disparity\n",
    "from network.loss import Total_Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initial parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set to GPU since we are using normal models\n",
    "device = device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'Running on {device}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Parameters\n",
    "nfpdm = 1  # (!) don't choose it too big because of memory limitations (!)\n",
    "N_inference = 2\n",
    "N_warmup = 1\n",
    "penal = False\n",
    "penal_beta = 1.\n",
    "batchsize = 1\n",
    "learned_metric = 'LIN'\n",
    "split = '1'\n",
    "show = False\n",
    "do_warmup = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to pfmaps (DW CONV results) and ofmaps before activation function (PW CONV results)\n",
    "fmaps = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size_mb(model: torch.nn.Module) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the size of a PyTorch model in megabytes (MB), including quantized models.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The PyTorch model.\n",
    "\n",
    "    Returns:\n",
    "        float: Size of the model in megabytes (MB).\n",
    "    \"\"\"\n",
    "    total_size_bytes = 0\n",
    "\n",
    "    # Iterate over all parameters\n",
    "    for param in model.parameters():\n",
    "        if param.is_quantized:\n",
    "            # For quantized tensors, calculate size based on the underlying data type\n",
    "            if param.dtype == torch.qint8:\n",
    "                # qint8 uses 1 byte per element\n",
    "                total_size_bytes += param.nelement() * 1\n",
    "            elif param.dtype == torch.quint8:\n",
    "                # quint8 also uses 1 byte per element\n",
    "                total_size_bytes += param.nelement() * 1\n",
    "            elif param.dtype == torch.qint32:\n",
    "                # qint32 uses 4 bytes per element\n",
    "                total_size_bytes += param.nelement() * 4\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported quantized dtype: {param.dtype}\")\n",
    "        else:\n",
    "            # For regular tensors, calculate size as usual\n",
    "            total_size_bytes += param.nelement() * param.element_size()\n",
    "\n",
    "    # Iterate over all buffers\n",
    "    for buffer in model.buffers():\n",
    "        if buffer.is_quantized:\n",
    "            # For quantized buffers, calculate size based on the underlying data type\n",
    "            if buffer.dtype == torch.qint8:\n",
    "                total_size_bytes += buffer.nelement() * 1\n",
    "            elif buffer.dtype == torch.quint8:\n",
    "                total_size_bytes += buffer.nelement() * 1\n",
    "            elif buffer.dtype == torch.qint32:\n",
    "                total_size_bytes += buffer.nelement() * 4\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported quantized dtype: {buffer.dtype}\")\n",
    "        else:\n",
    "            # For regular buffers, calculate size as usual\n",
    "            total_size_bytes += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    # Convert bytes to megabytes\n",
    "    total_size_mb = total_size_bytes / (1024 * 1024)\n",
    "    return total_size_mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nth_sample(dataloader: DataLoader, n: int):\n",
    "    \"\"\"\n",
    "    Get the N-th sample from a PyTorch DataLoader.\n",
    "\n",
    "    Args:\n",
    "        dataloader (torch.utils.data.DataLoader): The DataLoader to retrieve the sample from.\n",
    "        n (int): The sample index to retrieve.\n",
    "\n",
    "    Returns:\n",
    "        The N-th sample (data, target) tuple.\n",
    "    \"\"\"\n",
    "    for i, sample in enumerate(dataloader):\n",
    "        if i == n:\n",
    "            return sample  # Return the N-th sample\n",
    "    raise IndexError(\"Index out of range in DataLoader.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_eval(net, loss_module, data_loader, learned_metric = 'LIN'):\n",
    "    '''\n",
    "    Evaluate network accuracy as defined by the original authors of StereoSpike\n",
    "        - Only for binary event frames\n",
    "\n",
    "    Arg:\n",
    "        net: network to evaluate\n",
    "        loss_module: loss function definition\n",
    "        data_loader: dataloader with the test dataset\n",
    "        learned_metric: parameter by default is 'LIN'\n",
    "\n",
    "    Returns:\n",
    "        Print results\n",
    "    '''\n",
    "    # Initialize values\n",
    "    running_test_loss = 0\n",
    "    running_test_MDE = 0\n",
    "    running_test_OPA = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sample in tqdm(data_loader):\n",
    "\n",
    "            init_pots, warmup_chunks_left, warmup_chunks_right, test_chunks_left, test_chunks_right, label = sample\n",
    "            init_pots = init_pots.to(device)\n",
    "            warmup_chunks_left = warmup_chunks_left.to(device, dtype=torch.float)\n",
    "            warmup_chunks_right = warmup_chunks_right.to(device, dtype=torch.float)\n",
    "            test_chunks_left = test_chunks_left.to(device, dtype=torch.float)\n",
    "            test_chunks_right = test_chunks_right.to(device, dtype=torch.float)\n",
    "            label = label.to(device)\n",
    "\n",
    "            warmup_chunks, test_chunks = net.reformat_input_data(warmup_chunks_left, warmup_chunks_right,\n",
    "                                                                test_chunks_left, test_chunks_right)\n",
    "\n",
    "            functional.reset_net(net)\n",
    "\n",
    "            # No warmup\n",
    "            # if do_warmup:\n",
    "            #     net(warmup_chunks_left, warmup_chunks_right)\n",
    "\n",
    "            # Apply a binary mask to find all values >= 1 (True/False results)\n",
    "            # then get back to the original data type.\n",
    "            test_evframe = (test_chunks >= 1).to(test_chunks.dtype)\n",
    "\n",
    "            # Inference\n",
    "            pred, spks = net(test_evframe)     \n",
    "\n",
    "            # Loss calculation\n",
    "            loss = loss_module(pred, label, spks)\n",
    "            net.detach()\n",
    "\n",
    "            # go to linear depth to calculate MDE\n",
    "            if learned_metric == 'LIN':\n",
    "                lin_pred = pred[0]\n",
    "            elif learned_metric == 'LOG':\n",
    "                lin_pred = log_to_lin_depths(pred[0])\n",
    "            elif learned_metric == 'DISP':\n",
    "                lin_pred = disparity_to_depth(pred[0])\n",
    "            MDE = MeanDepthError_original(lin_pred, label)\n",
    "\n",
    "            # go to disparity to calculate 1PA metric\n",
    "            pred_disp = depth_to_disparity(lin_pred)\n",
    "            gt_disp = depth_to_disparity(label)\n",
    "\n",
    "            running_test_loss += loss.item() / test_chunks_left.size(0)\n",
    "            running_test_MDE += MDE\n",
    "            running_test_OPA += OnePixelAccuracy(pred_disp, gt_disp)\n",
    "            \n",
    "    epoch_test_loss = running_test_loss / len(data_loader)\n",
    "    epoch_test_MDE = running_test_MDE / len(data_loader)\n",
    "    epoch_test_OPA = running_test_OPA / len(data_loader)\n",
    "    test_epoch_summary = \"Loss: {}, Mean Depth Error (m): {}, One-Pixel Accuracy: {}\\n\".format(\n",
    "        epoch_test_loss, epoch_test_MDE, epoch_test_OPA)\n",
    "    print(f'Number of samples tested: {len(data_loader)}')\n",
    "    print(test_epoch_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "- Load the preprocessed test dataset.\n",
    "    - Mini dataset with a few samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/icds_asbc/Projects/distilled_q_stereospike/StereoSpike_Test\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(\"Current working directory:\", cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed dataset\n",
    "# train_set = torch.load('./datasets/MVSEC/data/indoor_post/train_set.pt')\n",
    "test_set = torch.load('./datasets/MVSEC/mini_data/indoor_post/mini_test_set.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in Test Dataloader: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create corresponding dataloader\n",
    "# train_data_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "#                                                 batch_size=batchsize,\n",
    "#                                                 shuffle=True,\n",
    "#                                                 drop_last=True,\n",
    "#                                                 pin_memory=True)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                               batch_size=1,\n",
    "                                               shuffle=False,\n",
    "                                               drop_last=True,\n",
    "                                               pin_memory=True)\n",
    "\n",
    "print(f'Number of elements in Test Dataloader: {len(test_data_loader)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n",
    "- Use the fixed network: Simplified Full-Precision without Skip Connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function definition\n",
    "loss_module = Total_Loss(alpha=0.5, scale_weights=(1., 1., 1., 1.), penalize_spikes=penal, beta=penal_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified_StereoSpike_NoSkip(\n",
      "  (surrogate_fct): ATan(alpha=2.0, spiking=True)\n",
      "  (bottom): Sequential(\n",
      "    (0): Conv2d(4, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=4, bias=False)\n",
      "    (1): Conv2d(4, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=32, bias=False)\n",
      "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=64, bias=False)\n",
      "    (1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=128, bias=False)\n",
      "    (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=256, bias=False)\n",
      "    (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (bottleneck): Sequential(\n",
      "    (0): SIMPLIFIED_SeparableSEWResBlock_noskip(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512, bias=False)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512, bias=False)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): SIMPLIFIED_SeparableSEWResBlock_noskip(\n",
      "      (conv1): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512, bias=False)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (conv2): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512, bias=False)\n",
      "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv4): Sequential(\n",
      "    (0): SeparableNNConvUpsampling(\n",
      "      (up): Sequential(\n",
      "        (0): UpsamplingNearest2d(size=(39, 50), mode='nearest')\n",
      "        (1): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
      "        (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv3): Sequential(\n",
      "    (0): SeparableNNConvUpsampling(\n",
      "      (up): Sequential(\n",
      "        (0): UpsamplingNearest2d(size=(71, 93), mode='nearest')\n",
      "        (1): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), groups=256, bias=False)\n",
      "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv2): Sequential(\n",
      "    (0): SeparableNNConvUpsampling(\n",
      "      (up): Sequential(\n",
      "        (0): UpsamplingNearest2d(size=(136, 179), mode='nearest')\n",
      "        (1): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), groups=128, bias=False)\n",
      "        (2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (deconv1): Sequential(\n",
      "    (0): SeparableNNConvUpsampling(\n",
      "      (up): Sequential(\n",
      "        (0): UpsamplingNearest2d(size=(266, 352), mode='nearest')\n",
      "        (1): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), groups=64, bias=False)\n",
      "        (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (predict_depth4): SeparableNNConvUpsampling(\n",
      "    (up): Sequential(\n",
      "      (0): UpsamplingNearest2d(size=(266, 352), mode='nearest')\n",
      "      (1): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), groups=256)\n",
      "      (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (predict_depth3): SeparableNNConvUpsampling(\n",
      "    (up): Sequential(\n",
      "      (0): UpsamplingNearest2d(size=(266, 352), mode='nearest')\n",
      "      (1): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), groups=128)\n",
      "      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (predict_depth2): SeparableNNConvUpsampling(\n",
      "    (up): Sequential(\n",
      "      (0): UpsamplingNearest2d(size=(266, 352), mode='nearest')\n",
      "      (1): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), groups=64)\n",
      "      (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (predict_depth1): SeparableNNConvUpsampling(\n",
      "    (up): Sequential(\n",
      "      (0): UpsamplingNearest2d(size=(266, 352), mode='nearest')\n",
      "      (1): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), groups=32)\n",
      "      (2): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the simplified network without skip connections\n",
    "net_s_nskip = Simplified_StereoSpike_NoSkip(input_chans=2*2*1, tau=3., v_threshold=1.0, v_reset=0.0, use_plif=True, multiply_factor=10., \n",
    "                                            surrogate_function=surrogate.ATan(), learnable_biases=False).to(device)\n",
    "\n",
    "# Load the pretrained model (specify the cpu in this case)\n",
    "net_s_nskip.load_state_dict(torch.load('./results/checkpoints/simplified_stereospike_NoSkip.pth', map_location=torch.device(device)))\n",
    "net_s_nskip.eval()\n",
    "\n",
    "print(net_s_nskip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified Full-precision Model (No skip connections) size: 6.075729 MB\n"
     ]
    }
   ],
   "source": [
    "# Calculate the size of the model\n",
    "model_size_mb = get_model_size_mb(net_s_nskip)\n",
    "print(f\"Simplified Full-precision Model (No skip connections) size: {model_size_mb:.6f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- Use mini test dataset on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/home/icds_asbc/anaconda3/envs/SpikingJelly_CPU_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples tested: 5\n",
      "Loss: 1.1904663562774658, Mean Depth Error (m): 0.14567741751670837, One-Pixel Accuracy: 33.786444664001465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc_eval(net_s_nskip, loss_module, test_data_loader, learned_metric = 'LIN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpikingJelly_CPU_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
